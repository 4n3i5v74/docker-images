**[`Main Page`](0. maintainers-guide.md)** / **[`Step 1`](1. create-bintray-repos-and-packages.md)** / **[`Step 2`](2. create-tvh.ubuntu.build.deps.md)** / **[`Step 3`](3. create-private-bitbucket-repo.md)** / **[`Step 4`](4. create-private-docker-images.md)**

## Builder Setup Guide

Apt package builders for tvheadend on ubuntu. This guide is expressly for members of tvheadend project only.

<!-- START doctoc generated TOC please keep comment here to allow auto update -->
<!-- DON'T EDIT THIS SECTION, INSTEAD RE-RUN doctoc TO UPDATE -->
 

- [Builder Setup Guide](#builder-setup-guide)
  - [For Tvheadend developers only](#for-tvheadend-developers-only)
  - [Requirements](#requirements)
  - [Overview](#overview)
  - [Considerations for reliability / breakages etc](#considerations-for-reliability--breakages-etc)
    - [Other limitations](#other-limitations)
    - [Solution](#solution)
  - [Reliability - build triggers](#reliability---build-triggers)
  - [Package linking on bintray](#package-linking-on-bintray)
  - [How to adapt for Debian, openSUSE, Fedora, CentOS, Arch ?](#how-to-adapt-for-debian-opensuse-fedora-centos-arch-)

<!-- END doctoc generated TOC please keep comment here to allow auto update -->

### For Tvheadend developers only

If you are not involved with officially distributing tvheadend software, there is no reason to go to this trouble of building apt packages of tvheadend. You should instead just download and enjoy the official pre-built tvheadend APT packages. Available from:

https://tvheadend.org/projects/tvheadend/wiki/AptRepository

It is not necessary, and a greate waste of resources to create duplicate additional server loads which build exaclty the same packages as are already being officially provided by the tvheadend project.

### Requirements

You will need:

* A Github Account (https://github.com/)
* A Bitbucket account (https://bitbucket.org/)
* A Docker Hub account (https://hub.docker.com/)
* A Bintray account (https://bintray.com/)
* A cron job to trigger builds with your docker hub API key*.

Note:

* User accounts should all be registered under your own regular username. e.g. `dreamcat4`, `negge`, `perexg`, `proyaffle`, etc.

* An understanding of Git and Docker will be needed for managing this build process.

* The cron job (last step) should be run from a secure computer that you yourself control. As it requires access to your docker hub API key in plain text. The cron job does not build anything locally. It just triggers the remote server(s) to start a new build run.

### Overview

The basic steps are as follows:

**[`Step 1`](1. create-bintray-repos-and-packages.md)**

* Create bintray repos and packages for tvheadend
  * This is where the builder (a docker image) will upload our .deb packages to
* On bintray.com
  * Create 2 new Debian repos, named: `ubuntu-master` and `ubuntu-stable`
    * Copy all the same settings from https://bintray.com/dreamcat4/
  * For each debian repo
    * Create a new 'tvheadend' package
      * Again, copy all the settings from https://bintray.com/dreamcat4/

**[`Step 2`](2. create-tvh.ubuntu.build.deps.md)**

* Create public docker image of tvheadend's build dependancies (optional)
  * On Github
    * Create git repo of build files for the `tvh.ubuntu.build.deps` docker image
  * On Dockerhub
    * Create new public repo named `tvh.ubuntu.build.deps`
      * As automated build
      * Get build trigger api token
  * On developer PC / server machine (via ssh) as regular user
    * Setup cron job to automatically re-build deps 1x per week OR 1x per month

**[`Step 3`](3. create-private-bitbucket-repo.md)**

* On Bitbucket
  * Create private git repo
    * Call it `dpi` - for 'Dockerhub private images'
* Initialize repo
  * Copy over `tvh.ubuntu.build` folder from public repo
* In local working copy of your `dpi` bitbucket private repo
  * Put your bintray usernname and API key into the 2 `Dockerfile`s
  * Push changes up to bitbucket

**[`Step 4`](4. create-private-docker-images.md)**

* Create private docker images to build the tvheadend APT packages for ubuntu
  * First create your 1 free private docker hub repo (you are only allowed 1)
    * So call it `dpi` - for 'Dockerhub Private Images' or something like that.
      * Create tagA named `tvh.build.ubuntu.master` --> builds docker image `tvh.build.ubuntu.master`
        * Point it to your bitbucket private repo
      * Create tagB named `tvh.build.ubuntu.stable` --> builds docker image `tvh.build.ubuntu.stable`
        * Point it to your bitbucket private repo

*As part of the image building process on Dockerhub, our Dockerfiles contain the necessary instructions to auto-upload the resulting .deb files to bintray.com.

We do not need to run or download these builder images to another computer. The work of the 'builder' images is already 100% done. The resulting `.deb` pkg binaries can be managed and distributed at bintray.com.*

### Considerations for reliability / breakages etc

This new build process may seem a bit fragile, considering that it requires multiple online services to all be functioning at around the same time. However if we break things down, we can assess the reliability of each service. And consider likely weak points.

* Github.com

Github has an established history and is pretty reliable. It recently suffered an unprecedented DDOS attack, and coped remarkably well. Oft Not only that, but the `tvheadend/tvheadend` git repo is hosted on github itself.

We use github for public version of the builder files. Which is not critical at build time. We also use github for building the dependancies base image (which has no api keys in it so can be fully public). However that image is not built very often, e.g. 1x per week or 1x per month. Which is not time-critical to the nightly builds whatsoever.

* Bitbucket.org

We depend on the github repo for 2 things:

* A free private repo (to include API keys in our build scripts)
* Nightly builds, it must be accessible at the time the build is triggered.

Butbucket is less well known - so I don't have any reliability data to share. However the service seem pretty reliable. It would be more of a concern is they took away free private repos for free OSS accounts.

Somehow that seems the more likely occurance than longtime service disruption of bitbucket.org.

At which point, there is not much we could do about it. Perhaps apply and request from eithe rBitbucket or Github support a private OSS repo on `tvheadend` account. Stating our need for holding API keys, and a public version (these files) also kept available without the api keys in them. Else host a private git repo on tvheadend.org using gitorious / gitlab / etc.

* Dockerhub

This is probably the most unreliable service which we are depending upon. At time of writing, dockerhub can quite frequently have some level service disruption. Either partial 'go slow' or full. However it never lasts too terribly long. Usually a few hours. Never for more than a day.

At worst, we might find a couple of days per month the nightly re-build was skipped. That will only affect us if there were new commits to the branch on the previous day. Once service is restored, we are back to the latest commit for those (master,stable) branches.

So generally speakign (for our purposes). Service reliability is 'good enough'. It also seems a small price to pay consider it is the dockerhub which is performing 100% all of the building task for us.

Of course, another possibility is that in future the Dockerhub may change it's policy and take away the '1 free private repo'. And we cannot predict that eventuality.

* Bintray

Bintray is a new service, so unfortunately I don't have any service reliability to pass on. However it *seems to be pretty solid*. As far as I can tell during the short time of testing it.

Since bintray actually hosts the APT repos for us. Then any widthwrawl of service would be problematic. However the fact that the bintray apt repo is de-coupled from the dockerhub builder images, means that we could move either service over independantly of the other one.

So if bintray goes away, we could still upload to another public APT repo somewhere else instead. *Or just do that as a matter of course now anyway so we upload to 2 public apt repos always.*

#### Other limitations

We cannot publically share the build logs of these automated builds. That is for 2 reasons:

* Dockerhub does let public URL of build log - because it is a private repo
* The build log containes (in plaintext) our bintray API key.

Therefore, it is strongly recommended to continue relying upon andoma's `doozer` build tool for publically providing tvheadend build logs. After all it works very well.

#### Solution

There is no way to predict when one of these online services becomes intermittend or unreliable, or may widthdraw from OSS use / becomes broken. So depending upon them may seem like a bad idea.

However the benefit is being open source, free, and no need to pay for private hosting is a high upside.

It is expected that by the time the builds eventually breaks, then launchpad.net should have had enough time to fully implement their new 'native' git-mirroring feature. Once that is in place, the Tvheadend project can look to build on launchpad.net's free PPA build farm. And make official ubuntu PPAs the regular way.

So effectively - this solution was meant to be a stop-gap between now & then. It will be for other or future tvheadend team members (or reliable 3rd party) to implement properly such PPA scheme for tvheadend in future.

### Reliability - build triggers

We must setup a cron job from other PC or server that is 'always online'. To `curl` a tigger token in a webhook (it is called a 'docker hub build trigger').

So if our local developer server goes offline or the cron job fails. Then the build will not be triggered. And no new packages for so many days until somebody notices / the cron job is fixed.

HOWEVER

The docker hub 'build triggers' feature has a policy, such that you cannot trigger the same build too often within a short period of time. Since then an errant script could overload their servers / build farm.

So perhaps what we might do is set up the same exact cron jobs on multple different developer machines, spread around. Then if one of those machines goes offline (or otherwise it's cron job stops working). Then presumably at least 1 other machine will still be working to trigger the build.

And if dockerhub recieves too many duplicate requests within a short time, then the extra requests should automatically be ignored.

That is something which should be looked into further. Sorry I have not had the chance yet.

### Package linking on bintray

It is not necessary to use an official 'tvheadend' user account(s) to build and upload the pkgs. I recommend to use your own user account name. Or otherwise create a 'machine account' that is shared amongst project team members. And is specifically being the builder / build task.

However it is a good idea to create an official 'tvheadend' user account on bintray.com. But not use it for uploading packages to. Instead, the official tvheadend account can be administered to 'link to' other bintray packages. This way it is very easy to switch over later to other packages (e.g. from other user or maintainer). And the official tvheadend account is just pointing to those other user's package.

Bintray package linking, see here:

https://bintray.com/docs/usermanual/uploads/uploads_exposingyourpackagetotheworldthroughmorepopularrepositorieslinkingapackage.html

### How to adapt for Debian, openSUSE, Fedora, CentOS, Arch ?

Well i'm only interested packages for the Ubuntu operating system. So have no motivation to build packages for other distros which I will likely never use.

However if you are someone else involved with tvheadned project who has a vested interest in making regular official (or semi-official) tvheadend pkgs for another popular linux distro then read one.

Bintray.com can also host rpm repos. To that aught to be a suitable destination for openSUSE, Fedora and Centos. Wheras Arch uses a different pkg format, however then the `pkg` files could be uploaded to some alternative destination.

So what are the changes to re-make everything for debian, centos, etc? In this example, we picker Centos as the target distro. But it could as easily be any other one.

* Create different kind of repo on bintray, e.g. for `rpm` type etc.
  * Still follow all the examples here e.g. when we show your how to make an ubuntu repo.
    * Just make a centos one instead e.g. named `centos-stable` etc.
      * Certain description fields are missing on other (non-debian) repo types

* Copy/rename the whole folder, from `tvh.ubuntu.build/`
  * To e.g. `tvh.centos.build/` etc.

* In the new base image `deps/` Dockerfile
  * Change the 1st line:
    * `FROM: ubuntu-debootstrap:14.04` ---> a decent minimal official docker base image of `centos` or `debian` etc. whatever.
  * Change the `apt-get install` ---> commands specific to your distro's package manager.

* In the `master/` and `stable/` `Dockerfile`s of the actual builder images
  * Change the 1st line:
    * `FROM: dreamcat4/tvh.build.ubuntu.deps` ---> `FROM: yourUsername/tvh.build.centos.deps`
  * Change the `Autobuild.sh` line, which builds a `.deb` file, to instead make your rpm or whatever other kind of pkg.
    * Try to keep all the same `./configure` args such as `----enable-libffmpeg_static` etc.
  * At bottom, when uploading `/out` files to your bintray repo:
    * You may need to change the file `find` commands, for example:
      * tvh_deb="$(find /out -name 'tvheadend_*.deb')" - matches on `.deb` file (not rpm, like you need it to).

And follow all the the other steps in this guide mostly the same. Just substituting different repo names / labels whenever needed.


